{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import torch\n",
    "import random\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms.transforms import RandomApply\n",
    "from core.transforms import GaussianBlur, TwoCropsTransform\n",
    "from core.custom_dataset import DatasetFolderSorted, ImageFolderSorted\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from agents.net import MLP, Encoder, SimSiam\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "augmentation = [\n",
    "    transforms.RandomResizedCrop(50, scale=(0.2, 1.)),\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
    "    ], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    'dataset/MiniWorld-FourRooms-v0/agent/D300',\n",
    "    TwoCropsTransform(\n",
    "        transforms.Compose(augmentation)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimSiam().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CosineSimilarity(dim=1).cuda()\n",
    "fix_pred_lr = False\n",
    "init_lr = 0.05\n",
    "\n",
    "if fix_pred_lr:\n",
    "    optim_params = [{'params': model.module.encoder.parameters(), 'fix_lr': False},\n",
    "                    {'params': model.module.predictor.parameters(), 'fix_lr': True}]\n",
    "else:\n",
    "    optim_params = model.parameters()\n",
    "\n",
    "optimizer = optim.Adam(optim_params, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][   0/1667]\tTime  0.207 ( 0.207)\tData  0.027 ( 0.027)\tLoss 0.0566 (0.0566)\n",
      "Epoch: [10][ 100/1667]\tTime  0.023 ( 0.025)\tData  0.020 ( 0.020)\tLoss -0.9998 (-0.9496)\n",
      "Epoch: [10][ 200/1667]\tTime  0.023 ( 0.024)\tData  0.019 ( 0.020)\tLoss -0.9997 (-0.9745)\n",
      "Epoch: [10][ 300/1667]\tTime  0.024 ( 0.024)\tData  0.020 ( 0.020)\tLoss -0.9997 (-0.9829)\n",
      "Epoch: [10][ 400/1667]\tTime  0.026 ( 0.023)\tData  0.023 ( 0.020)\tLoss -0.9998 (-0.9871)\n",
      "Epoch: [10][ 500/1667]\tTime  0.023 ( 0.023)\tData  0.020 ( 0.020)\tLoss -0.9999 (-0.9896)\n",
      "Epoch: [10][ 600/1667]\tTime  0.028 ( 0.023)\tData  0.025 ( 0.020)\tLoss -0.9997 (-0.9913)\n",
      "Epoch: [10][ 700/1667]\tTime  0.023 ( 0.023)\tData  0.020 ( 0.020)\tLoss -0.9999 (-0.9925)\n",
      "Epoch: [10][ 800/1667]\tTime  0.023 ( 0.023)\tData  0.020 ( 0.020)\tLoss -0.9998 (-0.9934)\n",
      "Epoch: [10][ 900/1667]\tTime  0.022 ( 0.023)\tData  0.018 ( 0.020)\tLoss -0.9998 (-0.9941)\n",
      "Epoch: [10][1000/1667]\tTime  0.023 ( 0.023)\tData  0.019 ( 0.020)\tLoss -0.9998 (-0.9947)\n",
      "Epoch: [10][1100/1667]\tTime  0.025 ( 0.023)\tData  0.021 ( 0.020)\tLoss -0.9998 (-0.9952)\n",
      "Epoch: [10][1200/1667]\tTime  0.023 ( 0.023)\tData  0.020 ( 0.020)\tLoss -0.9997 (-0.9955)\n",
      "Epoch: [10][1300/1667]\tTime  0.021 ( 0.023)\tData  0.018 ( 0.020)\tLoss -0.9996 (-0.9959)\n",
      "Epoch: [10][1400/1667]\tTime  0.021 ( 0.023)\tData  0.018 ( 0.020)\tLoss -0.9997 (-0.9961)\n",
      "Epoch: [10][1500/1667]\tTime  0.023 ( 0.023)\tData  0.020 ( 0.020)\tLoss -0.9998 (-0.9964)\n",
      "Epoch: [10][1600/1667]\tTime  0.022 ( 0.023)\tData  0.019 ( 0.020)\tLoss -0.9996 (-0.9966)\n"
     ]
    }
   ],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # if args.gpu is not None:\n",
    "        #     images[0] = images[0].cuda(args.gpu, non_blocking=True)\n",
    "        #     images[1] = images[1].cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        # compute output and loss\n",
    "        # print(len(images))\n",
    "        # input()\n",
    "        p1, p2, z1, z2 = model(x1=images[0].cuda(), x2=images[1].cuda())\n",
    "        # print(p1.size(), p2.size(), z1.size(), z2.size())\n",
    "        loss = -(criterion(p1, z2).mean() + criterion(p2, z1).mean()) * 0.5\n",
    "\n",
    "        losses.update(loss.item(), images[0].size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            progress.display(i)\n",
    "train(train_loader, model, criterion, optimizer, epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e2e8246255a260daa8af80185d2c5cff5556d2b33472f78e1dcb326d52dc230"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('irl_demo': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
